"""
AI Speech-to-Text Converter - Main Entry Point

A comprehensive AI speech recognition system supporting multiple audio formats.
Provides both MCP server capabilities and direct speech-to-text functionality.
"""

import os
import sys
import time
import json
import uuid
import asyncio
from pathlib import Path
from typing import List, Optional, Dict, Any
from mcp.server.fastmcp import FastMCP
from zhipu_speech_client import ZhipuSpeechClient
from network_diagnostic import NetworkDiagnostic

# Create an MCP server
mcp = FastMCP("AI Speech-to-Text Converter")

# Create directories for storing files
UPLOADS_DIR = Path("uploads")
UPLOADS_DIR.mkdir(exist_ok=True)

# Initialize clients
speech_client = ZhipuSpeechClient()

# Speech Recognition Entry Point
class SpeechRecognition:
    """ä¸»è¦çš„è¯­éŸ³è¯†åˆ«å…¥å£ç±»"""
    
    def __init__(self):
        self.speech_client = speech_client
        self.uploads_dir = UPLOADS_DIR
        
    
    
    def transcribe_audio(self, 
                        audio_path: str,
                        model: str = "glm-asr",
                        language: Optional[str] = None,
                        prompt: Optional[str] = None) -> Dict[str, Any]:
        """
        ä¸»è¦çš„è¯­éŸ³è½¬æ–‡æœ¬å…¥å£
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            model: ä½¿ç”¨çš„æ¨¡å‹ (glm-asr)
            language: éŸ³é¢‘è¯­è¨€
            prompt: æç¤ºè¯
            
        Returns:
            è½¬å½•ç»“æœ
        """
        return self.speech_client.transcribe_audio(
            audio_path=audio_path,
            model=model,
            language=language,
            prompt=prompt
        )
    
    def transcribe_with_timestamps(self, audio_path: str, model: str = "glm-asr") -> Dict[str, Any]:
        """å¸¦æ—¶é—´æˆ³çš„è¯­éŸ³è½¬æ–‡æœ¬"""
        return self.speech_client.transcribe_with_timestamps(audio_path, model)
    
    def transcribe_to_srt(self, audio_path: str, model: str = "glm-asr") -> Dict[str, Any]:
        """è½¬å½•ä¸ºSRTå­—å¹•æ ¼å¼"""
        return self.speech_client.transcribe_to_srt(audio_path, model)
    
    def batch_transcribe(self, audio_files: List[str], model: str = "glm-asr") -> Dict[str, Any]:
        """æ‰¹é‡è¯­éŸ³è½¬æ–‡æœ¬"""
        return self.speech_client.batch_transcribe(audio_files, model)

# åˆ›å»ºå…¨å±€è¯­éŸ³è¯†åˆ«å®ä¾‹
speech_recognition = SpeechRecognition()

@mcp.tool()
@mcp.tool()
def transcribe_audio_file(
    audio_path: str,
    model: str = "glm-asr",
    language: Optional[str] = None,
    prompt: Optional[str] = None,
    response_format: str = "json"
) -> Dict[str, Any]:
    """
    Transcribe audio file to text using Zhipu's speech-to-text API.
    
    Args:
        audio_path: Path to the audio file (.wav/.mp3, â‰¤25MB, â‰¤60s)
        model: Speech recognition model to use (glm-asr)
        language: Language of the audio (optional, e.g., 'zh', 'en')
        prompt: Optional prompt to guide the transcription
        response_format: Response format (json, text, srt, verbose_json, vtt)
    
    Returns:
        Dictionary with transcription results
    """
    try:
        if not audio_path:
            return {
                "success": False,
                "error": "Audio path cannot be empty"
            }
        
        # Check if file exists
        path = Path(audio_path)
        if not path.exists():
            # Try relative to uploads directory
            upload_path = UPLOADS_DIR / path.name
            if upload_path.exists():
                audio_path = str(upload_path)
            else:
                return {
                    "success": False,
                    "error": f"Audio file not found: {audio_path}"
                }
        
        result = speech_recognition.speech_client.transcribe_audio(
            audio_path=audio_path,
            model=model,
            language=language,
            prompt=prompt,
            response_format=response_format
        )
        return result
        
    except Exception as e:
        return {
            "success": False,
            "error": f"Audio transcription failed: {str(e)}"
        }

@mcp.tool()
def transcribe_with_timestamps(audio_path: str, model: str = "whisper-1") -> Dict[str, Any]:
    """
    Transcribe audio with detailed timestamps and segments.
    
    Args:
        audio_path: Path to the audio file
        model: Speech recognition model to use
    
    Returns:
        Dictionary with detailed transcription results including timestamps
    """
    try:
        if not audio_path:
            return {
                "success": False,
                "error": "Audio path cannot be empty"
            }
        
        # Check if file exists
        path = Path(audio_path)
        if not path.exists():
            # Try relative to uploads directory
            upload_path = UPLOADS_DIR / path.name
            if upload_path.exists():
                audio_path = str(upload_path)
            else:
                return {
                    "success": False,
                    "error": f"Audio file not found: {audio_path}"
                }
        
        result = speech_recognition.transcribe_with_timestamps(audio_path, model)
        return result
        
    except Exception as e:
        return {
            "success": False,
            "error": f"Timestamp transcription failed: {str(e)}"
        }

@mcp.tool()
@mcp.tool()
def transcribe_to_srt(audio_path: str, model: str = "glm-asr") -> Dict[str, Any]:
    """
    Transcribe audio to SRT subtitle format.
    
    Args:
        audio_path: Path to the audio file (.wav/.mp3, â‰¤25MB, â‰¤60s)
        model: Speech recognition model to use (glm-asr)
    
    Returns:
        Dictionary with SRT format transcription
    """
    try:
        if not audio_path:
            return {
                "success": False,
                "error": "Audio path cannot be empty"
            }
        
        # Check if file exists
        path = Path(audio_path)
        if not path.exists():
            # Try relative to uploads directory
            upload_path = UPLOADS_DIR / path.name
            if upload_path.exists():
                audio_path = str(upload_path)
            else:
                return {
                    "success": False,
                    "error": f"Audio file not found: {audio_path}"
                }
        
        result = speech_recognition.transcribe_to_srt(audio_path, model)
        return result
        
    except Exception as e:
        return {
            "success": False,
            "error": f"SRT transcription failed: {str(e)}"
        }

@mcp.tool()
@mcp.tool()
def batch_transcribe_audio(audio_files: List[str], model: str = "glm-asr") -> Dict[str, Any]:
    """
    Batch transcribe multiple audio files.
    
    Args:
        audio_files: List of audio file paths (.wav/.mp3, â‰¤25MB, â‰¤60s each)
        model: Speech recognition model to use (glm-asr)
    
    Returns:
        Dictionary with batch transcription results
    """
    try:
        if not audio_files:
            return {
                "success": False,
                "error": "Audio files list cannot be empty"
            }
        
        # Validate file paths
        valid_files = []
        for audio_path in audio_files:
            path = Path(audio_path)
            if path.exists():
                valid_files.append(str(path))
            else:
                # Try relative to uploads directory
                upload_path = UPLOADS_DIR / path.name
                if upload_path.exists():
                    valid_files.append(str(upload_path))
        
        if not valid_files:
            return {
                "success": False,
                "error": "No valid audio files found"
            }
        
        result = speech_recognition.batch_transcribe(valid_files, model)
        return result
        
    except Exception as e:
        return {
            "success": False,
            "error": f"Batch transcription failed: {str(e)}"
        }

@mcp.tool()
def get_audio_info(audio_path: str) -> Dict[str, Any]:
    """
    Get information about an audio file.
    
    Args:
        audio_path: Path to the audio file
    
    Returns:
        Dictionary with audio file information
    """
    try:
        if not audio_path:
            return {
                "success": False,
                "error": "Audio path cannot be empty"
            }
        
        # Check if file exists
        path = Path(audio_path)
        if not path.exists():
            # Try relative to uploads directory
            upload_path = UPLOADS_DIR / path.name
            if upload_path.exists():
                path = upload_path
            else:
                return {
                    "success": False,
                    "error": f"Audio file not found: {audio_path}"
                }
        
        # Get file information
        file_size = path.stat().st_size
        file_ext = path.suffix.lower()
        
        # Validate audio format
        validation = speech_client._validate_audio_file(str(path))
        
        return {
            "success": True,
            "filename": path.name,
            "path": str(path),
            "size": file_size,
            "size_mb": round(file_size / 1024 / 1024, 2),
            "format": file_ext,
            "validation": validation,
            "supported": validation["valid"]
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"Failed to get audio info: {str(e)}"
        }

@mcp.tool()
def test_speech_api(test_file: Optional[str] = None) -> Dict[str, Any]:
    """
    Test the speech-to-text API connection and functionality.
    
    Args:
        test_file: Optional path to a test audio file
    
    Returns:
        Dictionary with test results
    """
    try:
        # Test API connection
        connection_test = speech_client.test_connection()
        
        result = {
            "success": True,
            "connection_test": connection_test,
            "supported_formats": speech_client.get_supported_formats(),
            "available_models": list(speech_client.speech_models.keys())
        }
        
        # If test file provided, try transcription
        if test_file:
            path = Path(test_file)
            if path.exists() or (UPLOADS_DIR / path.name).exists():
                if not path.exists():
                    path = UPLOADS_DIR / path.name
                
                transcription_test = speech_client.transcribe_audio(str(path))
                result["transcription_test"] = transcription_test
            else:
                result["transcription_test"] = {
                    "success": False,
                    "error": f"Test file not found: {test_file}"
                }
        
        return result
        
    except Exception as e:
        return {
            "success": False,
            "error": f"API test failed: {str(e)}"
        }

@mcp.tool()
def upload_file(file_content: str, filename: str, encoding: str = "base64") -> Dict[str, Any]:
    """
    Upload an audio file to the server for transcription.
    
    Args:
        file_content: File content (base64 encoded or text)
        filename: Name of the file
        encoding: Encoding type (base64, text)
    
    Returns:
        Dictionary with upload result
    """
    try:
        if not file_content or not filename:
            return {
                "success": False,
                "error": "File content and filename are required"
            }
        
        # Create unique filename to avoid conflicts
        file_id = str(uuid.uuid4())[:8]
        name, ext = os.path.splitext(filename)
        unique_filename = f"{name}_{file_id}{ext}"
        file_path = UPLOADS_DIR / unique_filename
        
        # Save file based on encoding
        if encoding == "base64":
            import base64
            try:
                file_data = base64.b64decode(file_content)
                with open(file_path, 'wb') as f:
                    f.write(file_data)
            except Exception as e:
                return {
                    "success": False,
                    "error": f"Base64 decoding failed: {str(e)}"
                }
        else:
            # Assume text content
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(file_content)
        
        return {
            "success": True,
            "file_path": str(file_path),
            "filename": unique_filename,
            "size": file_path.stat().st_size,
            "timestamp": time.time()
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"File upload failed: {str(e)}"
        }

@mcp.tool()
def get_supported_formats() -> Dict[str, Any]:
    """
    Get list of supported audio formats for speech-to-text conversion.
    
    Returns:
        Dictionary with supported formats
    """
    try:
        formats = speech_client.get_supported_formats()
        models = speech_client.get_model_info()
        return {
            "success": True,
            "formats": formats,
            "models": list(models.keys()),
            "model_details": models
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Failed to get supported formats: {str(e)}"
        }

@mcp.tool()
def list_uploaded_files() -> Dict[str, Any]:
    """
    List all uploaded audio files available for transcription.
    
    Returns:
        Dictionary with file list
    """
    try:
        files = []
        for file_path in UPLOADS_DIR.iterdir():
            if file_path.is_file():
                files.append({
                    "filename": file_path.name,
                    "path": str(file_path),
                    "size": file_path.stat().st_size,
                    "modified": file_path.stat().st_mtime,
                    "type": file_path.suffix.lower()
                })
        
        # Sort by modification time (newest first)
        files.sort(key=lambda x: x["modified"], reverse=True)
        
        return {
            "success": True,
            "files": files,
            "total": len(files)
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"Failed to list files: {str(e)}"
        }

def run_interactive_mode():
    """è¿è¡Œäº¤äº’å¼è¯­éŸ³è½¬æ–‡æœ¬æ¨¡å¼"""
    print("=" * 60)
    print("ğŸ¤ AIè¯­éŸ³è½¬æ–‡æœ¬è½¬æ¢å™¨ - äº¤äº’æ¨¡å¼")
    print("=" * 60)
    print("æ”¯æŒçš„åŠŸèƒ½:")
    print("1. è¯­éŸ³è½¬æ–‡æœ¬")
    print("2. å¸¦æ—¶é—´æˆ³è½¬å½•")
    print("3. ç”ŸæˆSRTå­—å¹•")
    print("4. æ‰¹é‡è½¬å½•")
    print("5. æŸ¥çœ‹éŸ³é¢‘ä¿¡æ¯")
    print("6. æµ‹è¯•APIè¿æ¥")
    print("7. ç½‘ç»œè¯Šæ–­")
    print("8. å¯åŠ¨MCPæœåŠ¡å™¨")
    print("9. å¯åŠ¨WebæœåŠ¡å™¨")
    print("0. é€€å‡º")
    print("=" * 60)
    
    while True:
        try:
            choice = input("\nè¯·é€‰æ‹©åŠŸèƒ½ (0-9): ").strip()
            
            if choice == "0":
                print("ğŸ‘‹ å†è§!")
                break
            elif choice == "1":
                handle_audio_transcription()
            elif choice == "2":
                handle_timestamp_transcription()
            elif choice == "3":
                handle_srt_generation()
            elif choice == "4":
                handle_batch_transcription()
            elif choice == "5":
                handle_audio_info()
            elif choice == "6":
                handle_api_test()
            elif choice == "7":
                handle_network_diagnostic()
            elif choice == "8":
                print("ğŸ”§ å¯åŠ¨MCPæœåŠ¡å™¨...")
                mcp.run(transport="sse")
                break
            elif choice == "9":
                print("ğŸŒ å¯åŠ¨WebæœåŠ¡å™¨...")
                import subprocess
                subprocess.run([sys.executable, "speech_server.py"])
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥0-9")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§!")
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")

def handle_audio_transcription():
    """å¤„ç†éŸ³é¢‘è½¬å½•"""
    print("\nğŸ¤ è¯­éŸ³è½¬æ–‡æœ¬")
    audio_path = input("è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„: ").strip()
    if not audio_path:
        print("âŒ éŸ³é¢‘è·¯å¾„ä¸èƒ½ä¸ºç©º")
        return
    
    language = input("è¯·è¾“å…¥éŸ³é¢‘è¯­è¨€ (å¯é€‰ï¼Œå¦‚zh/en): ").strip() or None
    prompt = input("è¯·è¾“å…¥æç¤ºè¯ (å¯é€‰): ").strip() or None
    
    print("ğŸ” è½¬å½•ä¸­...")
    result = speech_recognition.transcribe_audio(audio_path, language=language, prompt=prompt)
    
    if result["success"]:
        print(f"âœ… è½¬å½•ç»“æœ:\n{result['text']}")
        if result.get('language'):
            print(f"æ£€æµ‹åˆ°çš„è¯­è¨€: {result['language']}")
    else:
        print(f"âŒ è½¬å½•å¤±è´¥: {result['error']}")

def handle_timestamp_transcription():
    """å¤„ç†å¸¦æ—¶é—´æˆ³è½¬å½•"""
    print("\nâ° å¸¦æ—¶é—´æˆ³è½¬å½•")
    audio_path = input("è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„: ").strip()
    if not audio_path:
        print("âŒ éŸ³é¢‘è·¯å¾„ä¸èƒ½ä¸ºç©º")
        return
    
    print("ğŸ” è½¬å½•ä¸­...")
    result = speech_recognition.transcribe_with_timestamps(audio_path)
    
    if result["success"]:
        print(f"âœ… è½¬å½•ç»“æœ:\n{result['text']}")
        if result.get('segments'):
            print("\næ—¶é—´æˆ³ä¿¡æ¯:")
            for segment in result['segments'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªç‰‡æ®µ
                print(f"  {segment.get('start', 0):.2f}s - {segment.get('end', 0):.2f}s: {segment.get('text', '')}")
    else:
        print(f"âŒ è½¬å½•å¤±è´¥: {result['error']}")

def handle_srt_generation():
    """å¤„ç†SRTå­—å¹•ç”Ÿæˆ"""
    print("\nğŸ“ ç”ŸæˆSRTå­—å¹•")
    audio_path = input("è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„: ").strip()
    if not audio_path:
        print("âŒ éŸ³é¢‘è·¯å¾„ä¸èƒ½ä¸ºç©º")
        return
    
    print("ğŸ” ç”Ÿæˆå­—å¹•ä¸­...")
    result = speech_recognition.transcribe_to_srt(audio_path)
    
    if result["success"]:
        print("âœ… SRTå­—å¹•ç”ŸæˆæˆåŠŸ!")
        srt_content = result.get('srt_content', result.get('text', ''))
        print("SRTå†…å®¹é¢„è§ˆ:")
        print(srt_content[:500] + "..." if len(srt_content) > 500 else srt_content)
        
        # ä¿å­˜SRTæ–‡ä»¶
        srt_path = Path(audio_path).with_suffix('.srt')
        with open(srt_path, 'w', encoding='utf-8') as f:
            f.write(srt_content)
        print(f"SRTæ–‡ä»¶å·²ä¿å­˜åˆ°: {srt_path}")
    else:
        print(f"âŒ å­—å¹•ç”Ÿæˆå¤±è´¥: {result['error']}")

def handle_batch_transcription():
    """å¤„ç†æ‰¹é‡è½¬å½•"""
    print("\nğŸ“ æ‰¹é‡è½¬å½•")
    print("è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (æ¯è¡Œä¸€ä¸ªï¼Œç©ºè¡Œç»“æŸ):")
    
    audio_files = []
    while True:
        path = input().strip()
        if not path:
            break
        audio_files.append(path)
    
    if not audio_files:
        print("âŒ æ²¡æœ‰è¾“å…¥ä»»ä½•æ–‡ä»¶")
        return
    
    print(f"ğŸ” æ‰¹é‡è½¬å½• {len(audio_files)} ä¸ªæ–‡ä»¶...")
    result = speech_recognition.batch_transcribe(audio_files)
    
    if result["success"]:
        print(f"âœ… æ‰¹é‡è½¬å½•å®Œæˆ!")
        print(f"æ€»è®¡: {result['total']}, æˆåŠŸ: {result['successful']}, å¤±è´¥: {result['failed']}")
        
        for item in result['results']:
            file_result = item['result']
            if file_result['success']:
                print(f"âœ… {item['file']}: {file_result['text'][:100]}...")
            else:
                print(f"âŒ {item['file']}: {file_result['error']}")
    else:
        print(f"âŒ æ‰¹é‡è½¬å½•å¤±è´¥: {result['error']}")

def handle_audio_info():
    """å¤„ç†éŸ³é¢‘ä¿¡æ¯æŸ¥çœ‹"""
    print("\nğŸ“Š éŸ³é¢‘ä¿¡æ¯")
    audio_path = input("è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„: ").strip()
    if not audio_path:
        print("âŒ éŸ³é¢‘è·¯å¾„ä¸èƒ½ä¸ºç©º")
        return
    
    result = get_audio_info(audio_path)
    
    if result["success"]:
        print("âœ… éŸ³é¢‘ä¿¡æ¯:")
        print(f"  æ–‡ä»¶å: {result['filename']}")
        print(f"  å¤§å°: {result['size_mb']} MB")
        print(f"  æ ¼å¼: {result['format']}")
        print(f"  æ”¯æŒè½¬å½•: {'æ˜¯' if result['supported'] else 'å¦'}")
        if not result['supported']:
            print(f"  é”™è¯¯: {result['validation']['error']}")
    else:
        print(f"âŒ è·å–ä¿¡æ¯å¤±è´¥: {result['error']}")

def handle_api_test():
    """å¤„ç†APIæµ‹è¯•"""
    print("\nğŸ”§ APIè¿æ¥æµ‹è¯•")
    test_file = input("è¯·è¾“å…¥æµ‹è¯•éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (å¯é€‰): ").strip() or None
    
    print("ğŸ” æµ‹è¯•ä¸­...")
    result = test_speech_api(test_file)
    
    if result["success"]:
        print("âœ… APIæµ‹è¯•ç»“æœ:")
        print(f"  è¿æ¥çŠ¶æ€: {'æ­£å¸¸' if result['connection_test']['success'] else 'å¤±è´¥'}")
        print(f"  å¯ç”¨æ¨¡å‹: {', '.join(result['available_models'])}")
        print(f"  æ”¯æŒæ ¼å¼: {result['supported_formats']}")
        
        if 'transcription_test' in result:
            trans_result = result['transcription_test']
            if trans_result['success']:
                print(f"  æµ‹è¯•è½¬å½•: {trans_result['text'][:100]}...")
            else:
                print(f"  æµ‹è¯•è½¬å½•å¤±è´¥: {trans_result['error']}")
    else:
        print(f"âŒ APIæµ‹è¯•å¤±è´¥: {result['error']}")

def handle_network_diagnostic():
    """å¤„ç†ç½‘ç»œè¯Šæ–­"""
    print("\nğŸ” ç½‘ç»œè¯Šæ–­")
    print("æ­£åœ¨æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIå¯è¾¾æ€§...")
    
    try:
        diagnostic = NetworkDiagnostic()
        diagnostic.run_full_diagnostic()
    except Exception as e:
        print(f"âŒ ç½‘ç»œè¯Šæ–­å¤±è´¥: {str(e)}")
        print("ğŸ’¡ å»ºè®®:")
        print("  1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("  2. ç¡®è®¤APIå¯†é’¥é…ç½®æ­£ç¡®")
        print("  3. å°è¯•ä½¿ç”¨VPNæˆ–ä»£ç†")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        if sys.argv[1] == "--mcp":
            print("ğŸ”§ å¯åŠ¨MCPæœåŠ¡å™¨æ¨¡å¼...")
            mcp.run(transport="sse")
        elif sys.argv[1] == "--web":
            print("ğŸŒ å¯åŠ¨WebæœåŠ¡å™¨æ¨¡å¼...")
            import subprocess
            subprocess.run([sys.executable, "speech_server.py"])
        elif sys.argv[1] == "--test":
            print("ğŸ§ª è¿è¡Œæµ‹è¯•...")
            import subprocess
            subprocess.run([sys.executable, "test_speech.py"])
        else:
            print("âŒ æœªçŸ¥å‚æ•°ï¼Œæ”¯æŒçš„å‚æ•°: --mcp, --web, --test")
    else:
        # é»˜è®¤è¿è¡Œäº¤äº’å¼æ¨¡å¼
        run_interactive_mode()